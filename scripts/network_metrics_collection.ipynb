{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx import Graph, DiGraph, simple_cycles\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from github import Github\n",
    "from IPython.display import display, HTML\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dic={'Android-Universal-Image-Loader':'nostra13/Android-Universal-Image-Loader',\n",
    "'antlr':'antlr/antlr4',\n",
    "'BroadleafCommerce':'BroadleafCommerce/BroadleafCommerce',\n",
    "'hazelcast':'hazelcast/hazelcast',\n",
    "'junit':'junit-team/junit',\n",
    "'mapdb':'jankotek/mapdb',\n",
    "'mcMMO':'mcMMO-Dev/mcMMO',\n",
    "'nasa_mct':'nasa/mct',\n",
    "'neo4j':'neo4j/neo4j',\n",
    "'netty':'netty/netty',\n",
    "'orientdb':'orientechnologies/orientdb',\n",
    "'titan':'thinkaurelius/titan',\n",
    "'dragula':'bevacqua/dragula',\n",
    "'sequelpro':'sequelpro/sequelpro',\n",
    "'wifiphisher':'wifiphisher/wifiphisher',\n",
    "'redshift':'jonls/redshift',\n",
    "'winget-cli':'microsoft/winget-cli',\n",
    "'PaddleDetection':'PaddlePaddle/PaddleDetection',\n",
    "'EyeWitness':'FortyNorthSecurity/EyeWitness',\n",
    "'photoprism':'photoprism/photoprism',\n",
    "'chartist_js':'gionkunz/chartist-js',\n",
    "'cleave_js':'nosir/cleave.js',\n",
    "'ossrs_srs':'ossrs/srs',\n",
    "'go_cloud':'google/go-cloud',\n",
    "'Windows_driver_samples':'microsoft/Windows-driver-samples',\n",
    "'sweetalert':'sweetalert2/sweetalert2',\n",
    "'files-community_Files':'files-community/Files',\n",
    "'gspread':'burnash/gspread',\n",
    "'prisma':'prisma/prisma',\n",
    "'d3_d3':'d3/d3',\n",
    "'snipe-it':'snipe/snipe-it',\n",
    "'klipper':'KevinOConnor/klipper',\n",
    "'TheAlgorithms_Java':'TheAlgorithms/Java',\n",
    "'lighthouse':'GoogleChrome/lighthouse',\n",
    "'aws_cli':'aws/aws-cli',\n",
    "'jquery':'jquery/jquery',\n",
    "'socketio':'socketio/socket.io',\n",
    "'expressjs':'expressjs/express',\n",
    "'swift_evolution':'apple/swift-evolution',\n",
    "'CNTK':'Microsoft/CNTK',\n",
    "'sqlmap':'sqlmapproject/sqlmap',\n",
    "'Arduino':'arduino/Arduino',\n",
    "'iina':'iina/iina',\n",
    "'corda':'corda/corda',\n",
    "'LightGBM':'microsoft/LightGBM',\n",
    "'MMdnn':'microsoft/MMdnn',\n",
    "'gson':'google/gson',\n",
    "'rstudio':'rstudio/rstudio',\n",
    "'turicreate':'apple/turicreate',\n",
    "'hive':'apache/hive',\n",
    "'intellij_plugins':'JetBrains/intellij-plugins',\n",
    "'eureka':'Netflix/eureka',\n",
    "'ignite':'apache/ignite',\n",
    "'hammerjs':'hammerjs/hammer.js',\n",
    "'postgres':'postgres/postgres',\n",
    "'gitbucket':'gitbucket/gitbucket',\n",
    "'mediaelement':'mediaelement/mediaelement',\n",
    "'graal':'oracle/graal',\n",
    "'fabric':'hyperledger/fabric',\n",
    "'jquery-mobile':'jquery/jquery-mobile',\n",
    "'Activiti':'Activiti/Activiti',\n",
    "'nopCommerce':'nopSolutions/nopCommerce',\n",
    "'zipline':'quantopian/zipline',\n",
    "'CoreNLP':'stanfordnlp/CoreNLP',\n",
    "'metabase':'metabase/metabase',\n",
    "'efcore':'dotnet/efcore',\n",
    "'harbor':'goharbor/harbor',\n",
    "'swoole-src':'swoole/swoole-src',\n",
    "'Signal-Android':'signalapp/Signal-Android',\n",
    "'tdesktop':'telegramdesktop/tdesktop',\n",
    "'ExoPlayer':'google/ExoPlayer',\n",
    "'kong':'Kong/kong',\n",
    "'ReactiveCocoa':'ReactiveCocoa/ReactiveCocoa',\n",
    "'checkstyle':'checkstyle/checkstyle',\n",
    "'rabbitmq-server':'rabbitmq/rabbitmq-server',\n",
    "'cesium':'CesiumGS/cesium',\n",
    "'ILSpy':'icsharpcode/ILSpy'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in repo_dic.items():\n",
    "    \n",
    "    df=pd.read_csv('data/commits/'+key+'.csv',index_col=0)\n",
    "    \n",
    "    #remove committers which is null values \n",
    "    df=df.dropna(subset=['committer']).reset_index(drop=True)\n",
    "\n",
    "    lst=df.SHA.unique().tolist()\n",
    "\n",
    "    # remove files changes greater than 200\n",
    "    df=df[df['files changed']<200].reset_index(drop=True) \n",
    "\n",
    "    # group commits based on 3 months\n",
    "    df['date'] = df['date'].apply(lambda _: datetime.datetime.strptime(_,'%Y-%m-%d %H:%M:%S'))\n",
    "    df=df.sort_values(by='date',ascending=False).reset_index(drop=True)   \n",
    "    # data collection threshold time\n",
    "    start_time = '5/15/21'     \n",
    "    # Define dates as datetime objects\n",
    "    start_time = datetime.datetime.strptime(start_time, '%m/%d/%y')\n",
    "    time_change = datetime.timedelta(weeks=13) \n",
    "    time_lst=[]\n",
    "    time=start_time\n",
    "    time_lst.append(time)\n",
    "    for s_date in df.date:\n",
    "        if time<df.iloc[-1].date:\n",
    "            break\n",
    "        time = time-time_change\n",
    "        time_lst.append(time)\n",
    "\n",
    "    #create commit groups\n",
    "    commitgroups=[]\n",
    "    for value in range(len(time_lst)-1):\n",
    "        df_interval=df [ (df.date<time_lst[value]) & (df.date>time_lst[value+1]) ]\n",
    "        commitgroups.extend(df_interval.groupby('filename')['committer'].unique().tolist())\n",
    "\n",
    "    #construct developer networks\n",
    "    %matplotlib inline\n",
    "    G_symmetric1 = nx.Graph()\n",
    "    for group in commitgroups:\n",
    "        test_list = group\n",
    "        res = [(a, b) for idx, a in enumerate(test_list) for b in test_list[idx + 1:]] \n",
    "        for x in res:    \n",
    "            G_symmetric1.add_edge(x[0],x[1])\n",
    "\n",
    "    #save commit groups characterized to DSN\n",
    "    a_file = open(\"data/commit_groups/commitGroups_\"+key+\".pkl\", \"wb\")\n",
    "    pickle.dump(commitgroups, a_file)\n",
    "    a_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network_metrics_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commitgroups_files = (glob.glob(\"data/commit_groups/*.pkl\"))\n",
    "\n",
    "# get network metrics for all constructed developer social networks in dataframe \n",
    "df_row=[]\n",
    "for file in commitgroups_files:\n",
    "\n",
    "    a_file = open(file, \"rb\")\n",
    "    commit_groups=pickle.load(a_file)\n",
    "    \n",
    "    %matplotlib inline\n",
    "    G_symmetric = nx.Graph()\n",
    "    for group in commit_groups:\n",
    "        test_list = group\n",
    "        res = [(a, b) for idx, a in enumerate(test_list) for b in test_list[idx + 1:]] \n",
    "        for x in res:    \n",
    "            G_symmetric.add_edge(x[0],x[1])\n",
    "    \n",
    "    G=[G_symmetric.subgraph(c).copy() for c in sorted(nx.connected_components(G_symmetric),key=len,reverse=True)][0]\n",
    "    \n",
    "    #find no of components in graph\n",
    "    components = dict(enumerate(nx.connected_components(G)))\n",
    "\n",
    "    #add different centrality metrics to a list\n",
    "    lst=[]\n",
    "    lst.append('--')\n",
    "    lst.append(len(G))\n",
    "    lst.append(G.number_of_edges())\n",
    "    lst.append(sum(dict(G.degree()).values())/float(len(G)))\n",
    "    lst.append(nx.average_clustering(G))\n",
    "    lst.append(nx.transitivity(G))\n",
    "    lst.append(nx.degree_pearson_correlation_coefficient(G)) \n",
    "    lst.append(nx.average_shortest_path_length(G))\n",
    "    lst.append(nx.diameter(G))\n",
    "    lst.append(nx.radius(G))\n",
    "    lst.append(nx.clustering(G))\n",
    "    lst.append(dict(nx.degree(G))) \n",
    "    lst.append(nx.eccentricity(G))\n",
    "    lst.append(nx.betweenness_centrality(G))\n",
    "    lst.append(nx.closeness_centrality(G))\n",
    "    lst.append(nx.eigenvector_centrality(G))\n",
    "    lst.append(nx.degree_centrality(G))\n",
    "    lst.append(nx.pagerank(G))\n",
    "    try:\n",
    "        hits_authorities=nx.hits(G)\n",
    "        lst.append(hits_authorities[0])\n",
    "        lst.append(hits_authorities[1])\n",
    "    except:\n",
    "        lst.append(dict())\n",
    "        lst.append(dict())\n",
    "    df_row.append(lst)   \n",
    "\n",
    "\n",
    "# create dataframe from collected list of metrics\n",
    "columns= ['repo','no_of_nodes','no_of_edges','average_degree','average_clustering_coefficient',\n",
    "          'transitivity','assortativity_coefficient','average_path_length','diameter','radius',\n",
    "          'clustering_coefficients','degree_of_nodes','eccentricities',\n",
    "          'betweenness_centralities','closeness_centralities','eigenvector_centralities',\n",
    "          'degree_centralities','page_rank','hubs','authorities']\n",
    "df=pd.DataFrame(df_row,columns=columns)\n",
    "df['repo']=commitgroups_files\n",
    "for index in df.index:\n",
    "    df['repo'][index]=df['repo'][index][13:-4]\n",
    "\n",
    "#convert the dictionary node values to lists \n",
    "for index in df.index:\n",
    "    df['clustering_coefficients'][index]=[round(num, 2) for num in list(df['clustering_coefficients'][index].values())]\n",
    "    df['degree_of_nodes'][index]=[round(num, 2) for num in list(df['degree_of_nodes'][index].values())]\n",
    "    df['eccentricities'][index]=[round(num, 2) for num in list(df['eccentricities'][index].values())]\n",
    "    df['betweenness_centralities'][index]=[round(num, 2) for num in list(df['betweenness_centralities'][index].values())]\n",
    "    df['closeness_centralities'][index]=[round(num, 2) for num in list(df['closeness_centralities'][index].values())]\n",
    "    df['eigenvector_centralities'][index]=[round(num, 2) for num in list(df['eigenvector_centralities'][index].values())]\n",
    "    df['degree_centralities'][index]=[round(num, 2) for num in list(df['degree_centralities'][index].values())]\n",
    "    df['page_rank'][index]=[round(num, 2) for num in list(df['page_rank'][index].values())]\n",
    "    df['hubs'][index]=[round(num, 2) for num in list(df['hubs'][index].values())]\n",
    "    df['authorities'][index]=[round(num, 2) for num in list(df['authorities'][index].values())]\n",
    "\n",
    "# add power law exponents\n",
    "#!pip install powerlaw\n",
    "#import powerlaw\n",
    "df['powerlaw_exponent']=df['degree_of_nodes'].apply(lambda x: powerlaw.Fit(x).power_law.alpha)\n",
    "\n",
    "# save dataframe\n",
    "a_file = open(\"data/Network_Metrics_real_dataset.pkl\", \"wb\")\n",
    "pickle.dump(df, a_file)\n",
    "a_file.close()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
